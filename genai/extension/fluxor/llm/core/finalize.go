package core

import (
	"context"
	_ "embed"
	"github.com/viant/agently/genai/agent/plan"
	"strings"
)

//go:embed prompt/finalize_prompt.vm
var finalizePromptTemplate string

type FinalizeInput struct {
	Query          string        `yaml:"query" json:"query"`                             // user query or question
	Model          string        `yaml:"model" json:"model"`                             // optional LLM model Name
	PromptTemplate string        `yaml:"promptTemplate" json:"promptTemplate,omitempty"` // optional custom prompt
	Context        string        `yaml:"context,omitempty" json:"context,omitempty"`     // additional context for the LLM
	Results        []plan.Result `yaml:"results" json:"results,omitempty"`               // structured step results for finalization
}

type FinalizeOutput struct {
	Answer string `json:"answer"` // final answer generated by the LLM
}

// finalize calls the LLM to produce the final answer based on results
func (s *Service) finalize(ctx context.Context, in, out interface{}) error {
	input := in.(*FinalizeInput)
	output := out.(*FinalizeOutput)

	modelName := input.Model
	if modelName == "" {
		modelName = s.defaultModel
	}

	promptTemplate := input.PromptTemplate
	if promptTemplate == "" {
		promptTemplate = finalizePromptTemplate
	}

	genInput := &GenerateInput{
		Model:    modelName,
		Template: promptTemplate,
		Bind: map[string]interface{}{
			"Query":   input.Query,
			"Context": input.Context,
			"Results": input.Results,
		},
	}
	genOutput := &GenerateOutput{}
	if err := s.Generate(ctx, genInput, genOutput); err != nil {
		return err
	}
	output.Answer = strings.TrimSpace(genOutput.Content)
	return nil
}
