default:
  model: openai_gpt-5
  embedder: openai_text
  agent: chatter
  toolCallResult:
    # Preview limit bytes for inline LLM binding (full body always stored)
    previewLimit: 8192
    # Chunk sizes for summarize/match tools
    summarizeChunk: 4096
    matchChunk: 1024
    # Model used for summarizing large tool results
    summaryModel: openai_gpt-5
    # Embedding model for semantic match (falls back to global default embedder)
    embeddingModel: openai_text
    # Optional system guide document path (file:// or absolute path). When set and a tool result overflows,
    # its content is injected into SystemDocuments for the LLM.
    systemGuidePath: ""
  match:
    # Default cap for auto full vs match decision and result capping
    # When a knowledge/MCP entry doesn't set maxFiles, this value is used.
    # If omitted, the runtime falls back to 5.
    maxFiles: 5
models:
  url: models
embedders:
  url: embedders
agents:
  url: agents
services:
  - system/exec
  - system/patch
  - printer/print
auth:
  enabled: true
  cookieName: agently_session
  ipHashKey: "dev-hmac-salt"     # any non-empty string; rotate later
  trustedProxies: ["127.0.0.1/32"]
  defaultUsername: devuser       # triggers silent local login from the UI
  local:
   enabled: true

#  oauth:
#    mode: bff
#    client:
#      configURL: idp_viant.enc|blowfish://default
